{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec202ada",
   "metadata": {},
   "source": [
    "## Assignment2 - Supervised Learning flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a2810",
   "metadata": {},
   "source": [
    "### Part 1 - Student details:\n",
    "* Please write the First Name and last 4 digits of the i.d. for each student. For example:\n",
    "<pre>Israel 9812</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# student 1:Yonatan 3212\n",
    "# student 2:Mor 3239\n",
    "# student 3:Yevgenia 3208\n",
    "# student 4:Adi 3186\n",
    "# student 5:Sahar 2091\n",
    "# (optional) student 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36672a",
   "metadata": {},
   "source": [
    "## Part 2 - Experiments\n",
    "You could add as many code cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c80de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7098585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_file_path = 'wine_train.csv'\n",
    "test_file_path = 'wine_test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "print(\"Train Set:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097afb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_df.describe()\n",
    "print(\"Train Data Statistics:\",train_stats)          # חישוב סטטיסטיקות עבור המשתנים המספריים בנתוני האימון\n",
    "\n",
    "corr_matrix = train_df.corr() \n",
    "print(\"\\nCorrelation Matrix:\\n\",corr_matrix)         # חישוב מטריצת הקורלציה של נתוני האימון\n",
    "\n",
    "print(\"\\nTrain Data Info:\")                          # הדפסת מידע על נתוני האימון\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nTest Data Info:\")                           # הדפסת מידע כללי על נתוני הבדיקה\n",
    "print(test_df.info())\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(train_df['alcohol'], train_df['proline'], alpha=0.7, s=100, color='Indianred')\n",
    "plt.title('Alcohol vs Proline')\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Proline')\n",
    "plt.grid(True)\n",
    "plt.show()                                           #עבור אחוז אלכוהול והפרולין scatterplot יצירת דיאגרמת \n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(train_df['alcohol'], bins=15, color='Darkred', edgecolor='black')\n",
    "plt.title('Distribution of Alcohol')\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()                                            # יצירת היסטוגרמה עבור שכיחות אחוזי האלכהול"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df['target']       # שמירת תווית התוצאה מהמאפיינים בנתוני האימון ובנתוני הבדיקה והוצאתן מהדאטאסט\n",
    "test_labels = test_df['target']\n",
    "train_features = train_df.drop(columns=['target'])\n",
    "test_features = test_df.drop(columns=['target'])\n",
    "\n",
    "numeric_features = train_features.select_dtypes(include=[np.number]).columns.tolist()    #סינון המאפיינים המספריים \n",
    "scaler = StandardScaler()  # יצירת מודל סקאלינג לנירמול בכדי להבטיח שכל הנתונים יהיו מנורמלים\n",
    "train_features[numeric_features] = scaler.fit_transform(train_features[numeric_features])  # תהליך נירמול על נתוני האימון\n",
    "test_features[numeric_features] = scaler.transform(test_features[numeric_features])  # תהליך נירמול על נתוני הבדיקה\n",
    "                                                                                \n",
    "categorical_features = train_features.select_dtypes(include=['object']).columns.tolist()\n",
    "if categorical_features:                 # סינון המאפיינים הקטגוריים\n",
    "    encoder = OneHotEncoder(sparse=False, drop='first')  # נשנה את כל המאפיינים הקטגורים למאפיינים מספריים \n",
    "    encoded_train = pd.DataFrame(encoder.fit_transform(train_features[categorical_features]),\n",
    "                                 columns=encoder.get_feature_names_out(categorical_features))  \n",
    "    encoded_test = pd.DataFrame(encoder.transform(test_features[categorical_features]),\n",
    "                                columns=encoder.get_feature_names_out(categorical_features)) \n",
    "    \n",
    "    train_features = pd.concat([train_features, encoded_train], axis=1)  #נכניס את המשתנים הקטגורים המקודדים\n",
    "    test_features = pd.concat([test_features, encoded_test], axis=1)     # לדאטא סטים כעמודות\n",
    "\n",
    "    train_features.drop(columns=categorical_features, inplace=True)  # נסיר את המאפיינים הקטגורים מהדאטאסט אימון ובדיקה\n",
    "    test_features.drop(columns=categorical_features, inplace=True) \n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_train_features = poly.fit_transform(train_features)  # יצירת מאפיינים פולינומיאליים עבור נתוני האימון והבדיקה\n",
    "poly_test_features = poly.transform(test_features)       # בכדי לשפר את יכולת המודל לזהות יחסים לא לינאריים\n",
    "\n",
    "X_train = poly_train_features\n",
    "X_test = poly_test_features\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()               # KNN יצירת אובייקט סיווג\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],                 # הגדרת הפרמטרים לבדיקה הכולל מספר קרובים אפשריים ופונקציית המשקל\n",
    "    'weights': ['uniform', 'distance'],\n",
    "}\n",
    "grid_search_knn = GridSearchCV(estimator=knn_model, param_grid=param_grid_knn, cv=5, scoring='accuracy')\n",
    "grid_search_knn.fit(X_train, y_train)            # KNN לחיפוש פרמטרים אופטימאלים עבור סיווג GridSearchCV יצירת אובייקט\n",
    "\n",
    "print(\"Best Parameters for KNN:\", grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier()         # DecisionTree יצירת אובייקט סיווג\n",
    "param_grid_tree = {\n",
    "    'max_depth': [None, 10, 20, 30],          # הגדרת הפרמטרים לבדיקה הכוללעומק מקסימלי של העץ ופיצול צמתים מינימאלי\n",
    "    'min_samples_split': [2, 10, 20]\n",
    "}\n",
    "grid_search_tree = GridSearchCV(estimator=tree_model, param_grid=param_grid_tree, cv=5, scoring='accuracy')\n",
    "grid_search_tree.fit(X_train, y_train)    # DecisionTree לחיפוש פרמטרים אופטימאלים עבור סיווג GridSearchCV יצירת אובייקט\n",
    "\n",
    "best_params_tree = grid_search_tree.best_params_\n",
    "\n",
    "print(\"Best Parameters for the Decision Tree:\", best_params_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1_scorer = make_scorer(f1_score, average='macro')        # f1_scores יצירת הערכת ביצועים למודלים לפי שיטת ממוצע  \n",
    "\n",
    "model_options = ['KNN', 'Decision Tree']    #בדיקת שני הסיווגים לפי כמות  קירובים אפשריים ופונקציית המשקל\n",
    "                                            # או במקרה של עץ ההחלטה לפי עומק מקסימלי של העץ וכמות פיצולים מינימאלית\n",
    "hyperparameters = { \n",
    "    'KNN': {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']},\n",
    "    'Decision Tree': {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 10, 20]}\n",
    "}\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for model_option in model_options:                           #יצירת לולאה אשר תבדוק את כל המקרים של כל סיווג\n",
    "    if model_option == 'KNN':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_option == 'Decision Tree':\n",
    "        model = DecisionTreeClassifier()\n",
    "        \n",
    "    param_grid = hyperparameters[model_option]\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=macro_f1_scorer)\n",
    "    grid_search.fit(X_train, y_train)   #לחיפוש פרמטרים אופטימאלים עבור הסיווג הנבדק ברגע זה GridSearchCV יצירת אובייקט\n",
    "                                        #5 fold cross validation מסמל את שיטת ה cv=5\n",
    "    \n",
    "   \n",
    "    best_score = grid_search.best_score_                     # קבלת התוצאות הטובות ביותר והוספתם לרשימת התוצאות\n",
    "    best_params = grid_search.best_params_\n",
    "    results_list.append({'Model': model_option,\n",
    "                         'Hyperparameters': best_params,\n",
    "                         'Macro-average-f1': best_score})\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d97f11",
   "metadata": {},
   "source": [
    "## Part 3 - Training flow\n",
    "Use the best combination of feature engineering, model (algorithm and hyperparameters) from the experiment part (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93713ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_combination = results_df.loc[results_df['Macro-average-f1'].idxmax()]    #בחירת השורה הטובה ביותר מההשוואה\n",
    "\n",
    "if best_combination['Model'] == 'KNN':                #אז ניצור אובייקט עם הנתונים שלו KNN במידה והסיווג היותר טוב הוא\n",
    "    model = KNeighborsClassifier(**best_combination['Hyperparameters'])         \n",
    "elif best_combination['Model'] == 'Decision Tree':    #אז ניצור אובייקט עם הנתונים שלו Decision Tree במידה והסיווג היותר טוב הוא\n",
    "    model = DecisionTreeClassifier(**best_combination['Hyperparameters'])\n",
    "\n",
    "model.fit(X_train, y_train)       # נאמן את המודל עם נתוני האימון\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ab902",
   "metadata": {},
   "source": [
    "## Part 4 - Apply on test and show model performance estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9971aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)         #חיזוי נתוני הבדיקה עם המודל שאימנו\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)        # חישוב דיוק החיזוי \n",
    "test_f1_macro = f1_score(y_test, test_predictions, average='macro') #עבור נתוני הבדיקה f1-score חישוב ה\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Macro-average F1 Score:\", test_f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a56369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea42a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
